{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0d5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f3a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the core features (frozen schema)\n",
    "core_features = [\n",
    "    \"gpt2_perplexity\", \"type_token_ratio\", \"repeated_3gram_ratio\",\n",
    "    \"unique_2grams\", \"unique_3grams\", \"sentence_length_std\",\n",
    "    \"sentence_length_entropy\", \"burstiness_token_std\", \"burstiness_token_var\",\n",
    "    \"pos_transition_entropy\", \"punctuation_ratio\", \"avg_word_length\",\n",
    "    \"flesch_reading_ease\", \"pos_ratio_X\", \"repeated_2gram_ratio\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982a3c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_transition_entropy</th>\n",
       "      <th>gpt2_perplexity</th>\n",
       "      <th>avg_sentence_length_v2</th>\n",
       "      <th>sentence_length_entropy</th>\n",
       "      <th>repeated_2gram_ratio</th>\n",
       "      <th>unique_2grams</th>\n",
       "      <th>repeated_3gram_ratio</th>\n",
       "      <th>unique_3grams</th>\n",
       "      <th>burstiness_token_var</th>\n",
       "      <th>burstiness_token_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44680e7b-a3c5-4984-9dae-dc39371c4d3d</td>\n",
       "      <td>2f47f011-2a2a-47fb-8380-81bbfd3aea9f</td>\n",
       "      <td>2f47f011-2a2a-47fb-8380-81bbfd3aea9f</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article_deletion</td>\n",
       "      <td>reddit</td>\n",
       "      <td>Anyone else have or had this?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.734448</td>\n",
       "      <td>35.831509</td>\n",
       "      <td>14.7500</td>\n",
       "      <td>3.444685</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3.508151</td>\n",
       "      <td>1.873006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1022b415-d62d-4542-8b22-c32d6689b422</td>\n",
       "      <td>76cf3c61-aa65-49a3-b3a5-6fdba510104d</td>\n",
       "      <td>76cf3c61-aa65-49a3-b3a5-6fdba510104d</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alternative_spelling</td>\n",
       "      <td>books</td>\n",
       "      <td>Father Malachy's Miracle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.639839</td>\n",
       "      <td>30.296240</td>\n",
       "      <td>23.0625</td>\n",
       "      <td>3.921559</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>344.0</td>\n",
       "      <td>14.939022</td>\n",
       "      <td>3.865103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2dcca159-a72f-425b-a42d-8af9aa77b1ed</td>\n",
       "      <td>17548d1a-9ad1-4d65-b97e-6d022f1413bd</td>\n",
       "      <td>a821b653-e817-4478-bddc-8012757258e7</td>\n",
       "      <td>mistral</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>zero_width_space</td>\n",
       "      <td>reddit</td>\n",
       "      <td>Do i have to wait another 20 years?</td>\n",
       "      <td>The following is the full text of a post title...</td>\n",
       "      <td>...</td>\n",
       "      <td>3.807238</td>\n",
       "      <td>6.557842</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>0.634578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444307a2-81a6-43c3-98eb-75bd4db300a6</td>\n",
       "      <td>cdeaa1ba-cdcd-48b6-a711-2cd5e8f630ae</td>\n",
       "      <td>cdeaa1ba-cdcd-48b6-a711-2cd5e8f630ae</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>news</td>\n",
       "      <td>Ireland surge past Scots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.628694</td>\n",
       "      <td>55.334324</td>\n",
       "      <td>25.0800</td>\n",
       "      <td>4.470719</td>\n",
       "      <td>0.066895</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.015464</td>\n",
       "      <td>572.0</td>\n",
       "      <td>9.503216</td>\n",
       "      <td>3.082729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1bd9e19-e76b-47de-b147-8319409506a2</td>\n",
       "      <td>72c85ea8-e1ae-4a13-a75f-99022c62d5b2</td>\n",
       "      <td>72c85ea8-e1ae-4a13-a75f-99022c62d5b2</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>wiki</td>\n",
       "      <td>Saraswati Rane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.481764</td>\n",
       "      <td>40.634918</td>\n",
       "      <td>20.8750</td>\n",
       "      <td>2.872306</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.825852</td>\n",
       "      <td>1.351241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                         adv_source_id  \\\n",
       "0  44680e7b-a3c5-4984-9dae-dc39371c4d3d  2f47f011-2a2a-47fb-8380-81bbfd3aea9f   \n",
       "1  1022b415-d62d-4542-8b22-c32d6689b422  76cf3c61-aa65-49a3-b3a5-6fdba510104d   \n",
       "2  2dcca159-a72f-425b-a42d-8af9aa77b1ed  17548d1a-9ad1-4d65-b97e-6d022f1413bd   \n",
       "3  444307a2-81a6-43c3-98eb-75bd4db300a6  cdeaa1ba-cdcd-48b6-a711-2cd5e8f630ae   \n",
       "4  a1bd9e19-e76b-47de-b147-8319409506a2  72c85ea8-e1ae-4a13-a75f-99022c62d5b2   \n",
       "\n",
       "                              source_id    model decoding repetition_penalty  \\\n",
       "0  2f47f011-2a2a-47fb-8380-81bbfd3aea9f    human      NaN                NaN   \n",
       "1  76cf3c61-aa65-49a3-b3a5-6fdba510104d    human      NaN                NaN   \n",
       "2  a821b653-e817-4478-bddc-8012757258e7  mistral   greedy                 no   \n",
       "3  cdeaa1ba-cdcd-48b6-a711-2cd5e8f630ae    human      NaN                NaN   \n",
       "4  72c85ea8-e1ae-4a13-a75f-99022c62d5b2    human      NaN                NaN   \n",
       "\n",
       "                 attack  domain                                title  \\\n",
       "0      article_deletion  reddit        Anyone else have or had this?   \n",
       "1  alternative_spelling   books             Father Malachy's Miracle   \n",
       "2      zero_width_space  reddit  Do i have to wait another 20 years?   \n",
       "3                number    news             Ireland surge past Scots   \n",
       "4                number    wiki                       Saraswati Rane   \n",
       "\n",
       "                                              prompt  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1                                                NaN  ...   \n",
       "2  The following is the full text of a post title...  ...   \n",
       "3                                                NaN  ...   \n",
       "4                                                NaN  ...   \n",
       "\n",
       "  pos_transition_entropy gpt2_perplexity  avg_sentence_length_v2  \\\n",
       "0               5.734448       35.831509                 14.7500   \n",
       "1               5.639839       30.296240                 23.0625   \n",
       "2               3.807238        6.557842                178.0000   \n",
       "3               5.628694       55.334324                 25.0800   \n",
       "4               5.481764       40.634918                 20.8750   \n",
       "\n",
       "   sentence_length_entropy  repeated_2gram_ratio  unique_2grams  \\\n",
       "0                 3.444685              0.048780          154.0   \n",
       "1                 3.921559              0.057377          314.0   \n",
       "2                 0.634578              0.000000            0.0   \n",
       "3                 4.470719              0.066895          535.0   \n",
       "4                 2.872306              0.116129          134.0   \n",
       "\n",
       "   repeated_3gram_ratio  unique_3grams  burstiness_token_var  \\\n",
       "0              0.006135          162.0              3.508151   \n",
       "1              0.021918          344.0             14.939022   \n",
       "2              0.000000            0.0              0.000000   \n",
       "3              0.015464          572.0              9.503216   \n",
       "4              0.064935          144.0              1.825852   \n",
       "\n",
       "   burstiness_token_std  \n",
       "0              1.873006  \n",
       "1              3.865103  \n",
       "2              0.000000  \n",
       "3              3.082729  \n",
       "4              1.351241  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Update this path to where your CSV actually lives.\n",
    "file_path = r\"C:\\Users\\marco\\Desktop\\Thesis\\data\\processed\\train_sample_baseline.csv\"\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the first few rows to verify it loaded correctly\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9787b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"binary_label\"] = df[\"model\"].apply(lambda m: \"human\" if m == \"human\" else \"artificial\")\n",
    "df[\"binary_label_code\"] = (df[\"binary_label\"] == \"artificial\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba05c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 15\n",
      "Shape of X: (16000, 15)\n",
      "Series y unique values: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Extract X and y\n",
    "X = df[core_features]\n",
    "y = df[\"binary_label_code\"]  # or whatever your target column is named\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Number of features:\", len(core_features))\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Series y unique values:\", y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e415f7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline AUC (5‐fold CV) with all core features: 0.9392\n",
      "Individual fold AUCs: [0.9385 0.9379 0.9367 0.9415 0.9413]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 5‐fold CV on the full feature set\n",
    "baseline_scores = cross_val_score(clf, X, y, cv=5, scoring=\"roc_auc\")\n",
    "baseline_mean = baseline_scores.mean()\n",
    "\n",
    "print(f\"Baseline AUC (5‐fold CV) with all core features: {baseline_mean:.4f}\")\n",
    "print(\"Individual fold AUCs:\", np.round(baseline_scores, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967e8af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>cv_auc_without_feature</th>\n",
       "      <th>delta_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>burstiness_token_var</td>\n",
       "      <td>0.939841</td>\n",
       "      <td>-0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burstiness_token_std</td>\n",
       "      <td>0.939831</td>\n",
       "      <td>-0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repeated_2gram_ratio</td>\n",
       "      <td>0.939226</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>repeated_3gram_ratio</td>\n",
       "      <td>0.939028</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unique_2grams</td>\n",
       "      <td>0.938421</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unique_3grams</td>\n",
       "      <td>0.938306</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_word_length</td>\n",
       "      <td>0.938251</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentence_length_entropy</td>\n",
       "      <td>0.937718</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flesch_reading_ease</td>\n",
       "      <td>0.937069</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>punctuation_ratio</td>\n",
       "      <td>0.936452</td>\n",
       "      <td>0.002748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pos_ratio_X</td>\n",
       "      <td>0.936299</td>\n",
       "      <td>0.002901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pos_transition_entropy</td>\n",
       "      <td>0.936139</td>\n",
       "      <td>0.003061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>type_token_ratio</td>\n",
       "      <td>0.935666</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence_length_std</td>\n",
       "      <td>0.933478</td>\n",
       "      <td>0.005723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt2_perplexity</td>\n",
       "      <td>0.911056</td>\n",
       "      <td>0.028145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  cv_auc_without_feature  delta_auc\n",
       "0      burstiness_token_var                0.939841  -0.000641\n",
       "1      burstiness_token_std                0.939831  -0.000631\n",
       "2      repeated_2gram_ratio                0.939226  -0.000025\n",
       "3      repeated_3gram_ratio                0.939028   0.000173\n",
       "4             unique_2grams                0.938421   0.000779\n",
       "5             unique_3grams                0.938306   0.000894\n",
       "6           avg_word_length                0.938251   0.000950\n",
       "7   sentence_length_entropy                0.937718   0.001482\n",
       "8       flesch_reading_ease                0.937069   0.002131\n",
       "9         punctuation_ratio                0.936452   0.002748\n",
       "10              pos_ratio_X                0.936299   0.002901\n",
       "11   pos_transition_entropy                0.936139   0.003061\n",
       "12         type_token_ratio                0.935666   0.003534\n",
       "13      sentence_length_std                0.933478   0.005723\n",
       "14          gpt2_perplexity                0.911056   0.028145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_results = []\n",
    "\n",
    "for f in core_features:\n",
    "    # Create a reduced feature matrix without column f\n",
    "    X_sub = X.drop(columns=[f])\n",
    "    \n",
    "    # Recompute CV‐AUC on this reduced set\n",
    "    scores = cross_val_score(clf, X_sub, y, cv=5, scoring=\"roc_auc\")\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # ΔAUC: how much performance drops (positive => feature was helpful)\n",
    "    delta = baseline_mean - mean_score\n",
    "    \n",
    "    ablation_results.append({\n",
    "        \"feature\": f,\n",
    "        \"cv_auc_without_feature\": mean_score,\n",
    "        \"delta_auc\": delta\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort by delta_auc (ascending)\n",
    "ablation_df = pd.DataFrame(ablation_results)\n",
    "ablation_df = ablation_df.sort_values(by=\"delta_auc\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "ablation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805f3401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features you can consider removing (ΔAUC ≤ 0):\n",
      "['burstiness_token_var', 'burstiness_token_std', 'repeated_2gram_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Flag features that can be dropped: delta_auc <= 0\n",
    "to_drop = ablation_df.loc[ablation_df[\"delta_auc\"] <= 0, \"feature\"].tolist()\n",
    "print(\"Features you can consider removing (ΔAUC ≤ 0):\")\n",
    "print(to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52acf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned AUC (5‐fold CV) with 12 features: 0.9391\n",
      "Individual fold AUCs: [0.9395 0.9381 0.9353 0.9403 0.942 ]\n",
      "AUC change: 0.0001\n"
     ]
    }
   ],
   "source": [
    "pruned_features = [f for f in core_features if f not in to_drop]\n",
    "X_pruned = X[pruned_features]\n",
    "\n",
    "# 5‐fold CV on the pruned feature set\n",
    "scores_pruned = cross_val_score(clf, X_pruned, y, cv=5, scoring=\"roc_auc\")\n",
    "pruned_mean = scores_pruned.mean()\n",
    "\n",
    "print(f\"Pruned AUC (5‐fold CV) with {len(pruned_features)} features: {pruned_mean:.4f}\")\n",
    "print(\"Individual fold AUCs:\", np.round(scores_pruned, 4))\n",
    "print(f\"AUC change: {baseline_mean - pruned_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73616f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ablation results to 'ablation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "ablation_df.to_csv(\"ablation_results.csv\", index=False)\n",
    "print(\"Saved ablation results to 'ablation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd534efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned feature list to 'pruned_features.txt'\n"
     ]
    }
   ],
   "source": [
    "with open(\"pruned_features.txt\", \"w\") as f:\n",
    "    for feat in pruned_features:\n",
    "        f.write(feat + \"\\n\")\n",
    "print(\"Saved pruned feature list to 'pruned_features.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
