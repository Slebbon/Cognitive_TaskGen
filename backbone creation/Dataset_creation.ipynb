{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200aef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, configuration, and constants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# File paths \n",
    "TRAIN_CSV = r\"C:\\Users\\marco\\Desktop\\Thesis\\data\\raw\\raid_train.csv\"\n",
    "TEST_CSV  = r\"C:\\Users\\marco\\Desktop\\Thesis\\data\\raw\\raid_test.csv\"\n",
    "\n",
    "# Output files \n",
    "OUT_SMALL  = \"raid_sample_small.csv\"\n",
    "OUT_MEDIUM = \"raid_sample_medium.csv\"\n",
    "OUT_LARGE  = \"raid_sample_large.csv\"\n",
    "\n",
    "# Sampling sizes\n",
    "SIZE_SMALL  = 3000\n",
    "SIZE_MEDIUM = 12000\n",
    "SIZE_LARGE  = 60000\n",
    "\n",
    "# Length bin target weights (strict): 25% short, 25% medium, 50% long\n",
    "LENGTH_WEIGHTS = {\"short\": 0.25, \"medium\": 0.25, \"long\": 0.50}\n",
    "\n",
    "# Known AI models in RAID \n",
    "AI_MODELS = [\n",
    "    \"chatgpt\", \"gpt4\", \"gpt3\", \"gpt2\",\n",
    "    \"llama-chat\",\n",
    "    \"mistral\", \"mistral-chat\",\n",
    "    \"mpt\", \"mpt-chat\",\n",
    "    \"cohere\", \"cohere-chat\"\n",
    "]\n",
    "\n",
    "# Domains to exclude\n",
    "EXCLUDED_DOMAINS = {\"czech\", \"german\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b99ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization, diagnostics, and filtering for text-like content in a DataFrame column.\n",
    "\n",
    "import re, unicodedata, math\n",
    "from collections import Counter\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Remove zero-width, BOM, bidi, soft hyphen; also strip control chars (except \\t\\n\\r)\n",
    "HIDDEN_RE = re.compile(r\"[\\u200B-\\u200D\\uFEFF\\u00AD\\u200E\\u200F\\u202A-\\u202E\\u2060\\u2066-\\u2069]\")\n",
    "CTRL_RE   = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\")\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    s = HIDDEN_RE.sub(\"\", s)\n",
    "    s = CTRL_RE.sub(\"\", s)\n",
    "    s = s.replace(\"\\u00A0\", \" \")  # NBSP → space\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Tokenizer for alphabetic words with optional apostrophes (English/Italian adequate)\n",
    "WORD_RE = re.compile(r\"[^\\W\\d_]+(?:'[^\\W\\d_]+)?\", re.UNICODE)\n",
    "\n",
    "def text_diagnostics(s: str) -> dict:\n",
    "    s = s or \"\"\n",
    "    n_chars = len(s)\n",
    "    n_alpha = sum(c.isalpha() for c in s)\n",
    "    n_digit = sum(c.isdigit() for c in s)\n",
    "    n_punct = sum((not c.isalnum()) and (not c.isspace()) for c in s)\n",
    "\n",
    "    toks = WORD_RE.findall(s)\n",
    "    n_tok = len(toks)\n",
    "    avg_wl = (sum(len(t) for t in toks) / n_tok) if n_tok else float(\"nan\")\n",
    "    std_wl = (math.sqrt(sum((len(t)-avg_wl)**2 for t in toks)/n_tok) if n_tok else float(\"nan\"))\n",
    "\n",
    "    if n_chars:\n",
    "        counts = Counter(s)\n",
    "        probs = [v/n_chars for v in counts.values()]\n",
    "        ent = -sum(p*math.log(p, 2) for p in probs)\n",
    "        ent_norm = ent / math.log(max(2, len(counts)), 2)\n",
    "    else:\n",
    "        ent = float(\"nan\"); ent_norm = float(\"nan\")\n",
    "\n",
    "    return dict(\n",
    "        n_chars=n_chars, n_tok=n_tok,\n",
    "        alpha_ratio=(n_alpha/n_chars) if n_chars else 0.0,\n",
    "        digit_ratio=(n_digit/n_chars) if n_chars else 0.0,\n",
    "        punct_ratio=(n_punct/n_chars) if n_chars else 0.0,\n",
    "        avg_word_length=avg_wl,\n",
    "        std_word_length=std_wl,\n",
    "        entropy_bits=ent, entropy_norm=ent_norm\n",
    "    )\n",
    "\n",
    "def is_text_like(di: dict) -> Tuple[bool, List[str]]:\n",
    "    reasons = []\n",
    "    if di[\"n_chars\"] < 30: reasons.append(\"too_short_chars\")\n",
    "    if di[\"n_tok\"]   < 5:  reasons.append(\"too_few_tokens\")\n",
    "\n",
    "    awl = di[\"avg_word_length\"]\n",
    "    if (not isinstance(awl, float)) or math.isnan(awl) or awl < 2.0 or awl > 10.0:\n",
    "        reasons.append(\"avg_word_length_out_of_range\")\n",
    "\n",
    "    if di[\"alpha_ratio\"] < 0.55: reasons.append(\"low_alpha_ratio\")\n",
    "    if di[\"digit_ratio\"] > 0.30: reasons.append(\"high_digit_ratio\")\n",
    "    if di[\"punct_ratio\"] > 0.35: reasons.append(\"high_punct_ratio\")\n",
    "\n",
    "    en = di[\"entropy_norm\"]\n",
    "    if (not isinstance(en, float)) or math.isnan(en) or en < 0.35:\n",
    "        reasons.append(\"low_entropy\")\n",
    "\n",
    "    return (len(reasons) == 0, reasons)\n",
    "\n",
    "def apply_text_gate(df: pd.DataFrame, src_col: str = \"generation\") -> pd.DataFrame:\n",
    "    \"\"\"Create generation_clean, diagnostics, and gate flags. Filters to text-like only.\"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"generation_clean\"] = out[src_col].astype(str).map(normalize_text)\n",
    "\n",
    "    # diagnostics as columns\n",
    "    diags = out[\"generation_clean\"].map(text_diagnostics).apply(pd.Series)\n",
    "    out = pd.concat([out, diags], axis=1)\n",
    "\n",
    "    # decision + reason\n",
    "    decisions = diags.apply(lambda row: is_text_like(row.to_dict()), axis=1)\n",
    "    out[\"is_text_like\"] = decisions.map(lambda x: x[0])\n",
    "    out[\"not_text_reason\"] = decisions.map(lambda x: \";\".join(x[1]))\n",
    "\n",
    "    # filter\n",
    "    filtered = out[out[\"is_text_like\"]].copy()\n",
    "    \n",
    "    # CRITICAL: Replace generation with cleaned version before returning\n",
    "    filtered[\"generation\"] = filtered[\"generation_clean\"]\n",
    "    filtered = filtered.drop(columns=[\"generation_clean\"])\n",
    "    \n",
    "    filtered.reset_index(drop=True, inplace=True)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671b65",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     52\u001b[39m     df = apply_text_gate(df, src_col=\u001b[33m\"\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# adds generation_clean + diagnostics and filters to text-like\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m df = \u001b[43msafe_load_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_CSV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRows loaded:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[32m     59\u001b[39m df.head(\u001b[32m3\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36msafe_load_and_prepare\u001b[39m\u001b[34m(train_csv, test_csv)\u001b[39m\n\u001b[32m     49\u001b[39m df.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# --- normalize text and gate non-text ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m df = \u001b[43mapply_text_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# adds generation_clean + diagnostics and filters to text-like\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mapply_text_gate\u001b[39m\u001b[34m(df, src_col)\u001b[39m\n\u001b[32m     76\u001b[39m out[\u001b[33m\"\u001b[39m\u001b[33mgeneration_clean\u001b[39m\u001b[33m\"\u001b[39m] = out[src_col].astype(\u001b[38;5;28mstr\u001b[39m).map(normalize_text)\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# diagnostics as columns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m diags = \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration_clean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_diagnostics\u001b[49m\u001b[43m)\u001b[49m.apply(pd.Series)\n\u001b[32m     80\u001b[39m out = pd.concat([out, diags], axis=\u001b[32m1\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# decision + reason\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\.conda\\envs\\Tesi\\Lib\\site-packages\\pandas\\core\\series.py:4700\u001b[39m, in \u001b[36mSeries.map\u001b[39m\u001b[34m(self, arg, na_action)\u001b[39m\n\u001b[32m   4620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\n\u001b[32m   4621\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4622\u001b[39m     arg: Callable | Mapping | Series,\n\u001b[32m   4623\u001b[39m     na_action: Literal[\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4624\u001b[39m ) -> Series:\n\u001b[32m   4625\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4626\u001b[39m \u001b[33;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[32m   4627\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4698\u001b[39m \u001b[33;03m    dtype: object\u001b[39;00m\n\u001b[32m   4699\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4700\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4701\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor(new_values, index=\u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(\n\u001b[32m   4702\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4703\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\.conda\\envs\\Tesi\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\.conda\\envs\\Tesi\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtext_diagnostics\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m     31\u001b[39m toks = WORD_RE.findall(s)\n\u001b[32m     32\u001b[39m n_tok = \u001b[38;5;28mlen\u001b[39m(toks)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m avg_wl = (\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m)\u001b[49m / n_tok) \u001b[38;5;28;01mif\u001b[39;00m n_tok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m std_wl = (math.sqrt(\u001b[38;5;28msum\u001b[39m((\u001b[38;5;28mlen\u001b[39m(t)-avg_wl)**\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m toks)/n_tok) \u001b[38;5;28;01mif\u001b[39;00m n_tok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_chars:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     31\u001b[39m toks = WORD_RE.findall(s)\n\u001b[32m     32\u001b[39m n_tok = \u001b[38;5;28mlen\u001b[39m(toks)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m avg_wl = (\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m toks) / n_tok) \u001b[38;5;28;01mif\u001b[39;00m n_tok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m std_wl = (math.sqrt(\u001b[38;5;28msum\u001b[39m((\u001b[38;5;28mlen\u001b[39m(t)-avg_wl)**\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m toks)/n_tok) \u001b[38;5;28;01mif\u001b[39;00m n_tok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_chars:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def safe_load_and_prepare(train_csv: str, test_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads train and test (if present), concatenates, normalizes text fields,\n",
    "    excludes czech/german, labels source_type, de-duplicates, removes empty,\n",
    "    THEN applies a text-likeness gate and returns only text-like rows.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for p in [train_csv, test_csv]:\n",
    "        try:\n",
    "            tmp = pd.read_csv(p)\n",
    "            frames.append(tmp)\n",
    "        except Exception as e:\n",
    "            print(f\"[INFO] Could not load {p}: {e}\")\n",
    "    if not frames:\n",
    "        cols = [\"id\",\"adv_source_id\",\"source_id\",\"model\",\"decoding\",\"repetition_penalty\",\n",
    "                \"attack\",\"domain\",\"generation\"]\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # --- existing normalization of metadata ---\n",
    "    if \"model\" in df.columns:\n",
    "        df[\"model\"] = df[\"model\"].astype(str).str.strip().str.lower()\n",
    "    else:\n",
    "        df[\"model\"] = np.nan\n",
    "\n",
    "    if \"domain\" in df.columns:\n",
    "        df[\"domain\"] = df[\"domain\"].astype(str).str.strip().str.lower()\n",
    "        df = df[~df[\"domain\"].isin(EXCLUDED_DOMAINS)].copy()\n",
    "    else:\n",
    "        df[\"domain\"] = \"\"\n",
    "\n",
    "    # Define is_ai / source_type\n",
    "    df[\"is_ai\"] = df[\"model\"].isin(set(AI_MODELS))\n",
    "    df[\"source_type\"] = np.where(df[\"is_ai\"], \"ai\", \"human\")\n",
    "\n",
    "    # Ensure 'generation' exists and not only whitespace\n",
    "    if \"generation\" not in df.columns:\n",
    "        raise ValueError(\"The dataset is missing the 'generation' column which is required.\")\n",
    "    df[\"generation\"] = df[\"generation\"].astype(str)\n",
    "    df = df[df[\"generation\"].str.strip().astype(bool)].copy()\n",
    "\n",
    "    # De-duplicate\n",
    "    if \"id\" in df.columns:\n",
    "        df = df.drop_duplicates(subset=[\"id\"])\n",
    "    else:\n",
    "        df = df.drop_duplicates(subset=[\"generation\"])\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # --- normalize text and gate non-text ---\n",
    "    df = apply_text_gate(df, src_col=\"generation\")  # adds generation_clean + diagnostics and filters to text-like\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = safe_load_and_prepare(TRAIN_CSV, TEST_CSV)\n",
    "print(\"Rows loaded:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d8ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length_bin\n",
       "long      3133501\n",
       "short     1578114\n",
       "medium    1576205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length features and binning utilities (25% short, 25% medium, 50% long)\n",
    "\n",
    "def compute_length_features(df: pd.DataFrame, text_col: str = \"generation\") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # Use the column as-is (already cleaned by apply_text_gate)\n",
    "    out[\"n_tokens_ws\"] = out[text_col].fillna(\"\").map(lambda s: len(str(s).split()))\n",
    "    out[\"n_chars\"] = out[text_col].fillna(\"\").map(lambda s: len(str(s)))\n",
    "    return out\n",
    "\n",
    "def assign_length_bins(df: pd.DataFrame, token_col: str = \"n_tokens_ws\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign 'short' if <= 25th percentile, 'medium' if (25th, 50th], 'long' if > 50th.\n",
    "    This sets up the population so that sampling can enforce the exact 25/25/50 composition.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    if len(out) == 0:\n",
    "        out[\"length_bin\"] = pd.Categorical([], categories=[\"short\",\"medium\",\"long\"])\n",
    "        return out\n",
    "\n",
    "    p25 = np.percentile(out[token_col], 25)\n",
    "    p50 = np.percentile(out[token_col], 50)\n",
    "\n",
    "    def _bin(x):\n",
    "        if x <= p25:\n",
    "            return \"short\"\n",
    "        elif x <= p50:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"long\"\n",
    "\n",
    "    out[\"length_bin\"] = out[token_col].map(_bin)\n",
    "    out[\"length_bin\"] = pd.Categorical(out[\"length_bin\"], categories=[\"short\",\"medium\",\"long\"])\n",
    "    return out\n",
    "\n",
    "# Apply on the loaded df - this now operates on cleaned text\n",
    "df = compute_length_features(df, \"generation\")\n",
    "df = assign_length_bins(df, \"n_tokens_ws\")\n",
    "df[\"length_bin\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3d188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest remainder test: {'a': 3, 'b': 2, 'c': 5}\n"
     ]
    }
   ],
   "source": [
    "# Allocation helpers (largest remainder method) and proportional rounding\n",
    "\n",
    "def largest_remainder(target_total: int, weights: dict[str, float]) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Allocate 'target_total' into integer counts according to 'weights' (which should sum to 1),\n",
    "    using the Largest Remainder Method to ensure totals match exactly.\n",
    "    \"\"\"\n",
    "    if not weights:\n",
    "        return {}\n",
    "    keys = list(weights.keys())\n",
    "    raw = np.array([weights[k] for k in keys], dtype=float) * target_total\n",
    "    floors = np.floor(raw).astype(int)\n",
    "    remainder = target_total - floors.sum()\n",
    "    fracs = raw - floors\n",
    "    order = np.argsort(-fracs)  # descending by fractional remainder\n",
    "    alloc = floors.copy()\n",
    "    for i in range(max(0, remainder)):\n",
    "        alloc[order[i]] += 1\n",
    "    return {k: int(v) for k, v in zip(keys, alloc)}\n",
    "\n",
    "def proportional_weights(counts: dict[str, int]) -> dict[str, float]:\n",
    "    total = sum(counts.values())\n",
    "    if total <= 0:\n",
    "        n = len(counts)\n",
    "        return {k: 1.0 / n for k in counts} if n else {}\n",
    "    return {k: v / total for k, v in counts.items()}\n",
    "\n",
    "def proportional_allocation(target_total: int, available_counts: dict[str, int]) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Allocate target_total across keys proportionally to available_counts, capped by availability.\n",
    "    If some caps bind, redistribute the remainder among non-capped keys iteratively.\n",
    "    \"\"\"\n",
    "    remaining_total = target_total\n",
    "    remaining = available_counts.copy()\n",
    "    alloc = {k: 0 for k in available_counts}\n",
    "\n",
    "    while remaining_total > 0 and any(v > 0 for v in remaining.values()):\n",
    "        weights = proportional_weights(remaining)\n",
    "        step = largest_remainder(remaining_total, weights)\n",
    "        # Cap by availability\n",
    "        capped = {}\n",
    "        for k, v in step.items():\n",
    "            take = min(v, remaining[k])\n",
    "            capped[k] = take\n",
    "        # Update allocations\n",
    "        for k, take in capped.items():\n",
    "            alloc[k] += take\n",
    "            remaining[k] -= take\n",
    "        remaining_total = target_total - sum(alloc.values())\n",
    "        if remaining_total <= 0:\n",
    "            break\n",
    "        if not any(v > 0 for v in remaining.values()):\n",
    "            break\n",
    "\n",
    "    return alloc\n",
    "\n",
    "# Quick self-test\n",
    "print(\"Largest remainder test:\", largest_remainder(10, {\"a\":0.25,\"b\":0.25,\"c\":0.5}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038db4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Core stratified sampler\n",
    "\n",
    "def stratified_sample(\n",
    "    df: pd.DataFrame,\n",
    "    total_size: int,\n",
    "    length_weights: dict[str, float] = LENGTH_WEIGHTS,\n",
    "    ai_models_even: bool = True,\n",
    "    random_state: int = RANDOM_SEED\n",
    ") -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Create a stratified sample with:\n",
    "      - 50% human, 50% AI\n",
    "      - Length-bin distribution per 'length_weights' (e.g., 25/25/50)\n",
    "      - For AI: even across models if ai_models_even=True (among models present)\n",
    "      - Domains: proportional to availability within each (group × length_bin)\n",
    "    Returns: (sample_df, diagnostics_dict)\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        return df.copy(), {\"note\": \"Empty dataframe; run locally with data available.\"}\n",
    "\n",
    "    required_cols = {\"source_type\", \"length_bin\", \"domain\", \"generation\", \"model\"}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    work = df.dropna(subset=[\"length_bin\"]).copy()\n",
    "\n",
    "    # Split desired totals\n",
    "    half = total_size // 2\n",
    "    remainder = total_size - 2 * half  # handle odd totals if any\n",
    "    target_by_source = {\"human\": half, \"ai\": half + remainder}\n",
    "\n",
    "    # Within each source_type, allocate to length bins\n",
    "    length_targets = {s: largest_remainder(target_by_source[s], length_weights) for s in target_by_source}\n",
    "\n",
    "    picked_indices = []\n",
    "    debug_info = {\"by_source_length\": {}, \"by_model_length\": {}, \"by_domain\": {}}\n",
    "    rng_local = np.random.default_rng(random_state)\n",
    "\n",
    "    for source in [\"human\", \"ai\"]:\n",
    "        for lb, lb_target in length_targets[source].items():\n",
    "            subset = work[(work[\"source_type\"] == source) & (work[\"length_bin\"] == lb)]\n",
    "\n",
    "            if source == \"ai\" and ai_models_even:\n",
    "                # Even per AI model among those present in this length bin\n",
    "                present_models = sorted(set(subset[\"model\"]) & set(AI_MODELS))\n",
    "                if not present_models:\n",
    "                    continue\n",
    "                per_model = largest_remainder(lb_target, {m: 1/len(present_models) for m in present_models})\n",
    "                debug_info[\"by_model_length\"].setdefault(lb, {})[source] = per_model\n",
    "\n",
    "                for m, m_target in per_model.items():\n",
    "                    sub_m = subset[subset[\"model\"] == m]\n",
    "                    # Domain proportional allocation within this slice\n",
    "                    domain_counts = sub_m[\"domain\"].value_counts().to_dict()\n",
    "                    alloc_dom = proportional_allocation(m_target, domain_counts)\n",
    "\n",
    "                    for dom, take in alloc_dom.items():\n",
    "                        take = int(take)\n",
    "                        if take <= 0:\n",
    "                            continue\n",
    "                        candidates = sub_m[sub_m[\"domain\"] == dom]\n",
    "                        if len(candidates) == 0:\n",
    "                            continue\n",
    "                        take = min(take, len(candidates))\n",
    "                        chosen = candidates.sample(\n",
    "                            n=take,\n",
    "                            random_state=rng_local.integers(0, 1_000_000)\n",
    "                        ).index.tolist()\n",
    "                        picked_indices.extend(chosen)\n",
    "                        debug_info[\"by_domain\"].setdefault((source, lb, m), {})[dom] = take\n",
    "            else:\n",
    "                # HUMAN or AI without even split: directly allocate by domain\n",
    "                domain_counts = subset[\"domain\"].value_counts().to_dict()\n",
    "                alloc_dom = proportional_allocation(lb_target, domain_counts)\n",
    "                debug_info[\"by_source_length\"].setdefault(source, {})[lb] = alloc_dom\n",
    "\n",
    "                for dom, take in alloc_dom.items():\n",
    "                    take = int(take)\n",
    "                    if take <= 0:\n",
    "                        continue\n",
    "                    candidates = subset[subset[\"domain\"] == dom]\n",
    "                    if len(candidates) == 0:\n",
    "                        continue\n",
    "                    take = min(take, len(candidates))\n",
    "                    chosen = candidates.sample(\n",
    "                        n=take,\n",
    "                        random_state=rng_local.integers(0, 1_000_000)\n",
    "                    ).index.tolist()\n",
    "                    picked_indices.extend(chosen)\n",
    "\n",
    "    sample_df = work.loc[sorted(set(picked_indices))].copy()\n",
    "\n",
    "    shortfall = total_size - len(sample_df)\n",
    "    diagnostics = {\n",
    "        \"target_total\": total_size,\n",
    "        \"picked_total\": len(sample_df),\n",
    "        \"shortfall\": shortfall,\n",
    "        \"length_targets\": length_targets,\n",
    "        \"by_source_length\": debug_info.get(\"by_source_length\", {}),\n",
    "        \"by_model_length\": debug_info.get(\"by_model_length\", {}),\n",
    "    }\n",
    "    return sample_df, diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef967cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "raid_sample_small.csv 3000\n",
      "raid_sample_medium.csv 12000\n",
      "raid_sample_large.csv 60000\n"
     ]
    }
   ],
   "source": [
    "#  Orchestration to produce small/medium/large samples and save\n",
    "\n",
    "def run_all_samples(df_full: pd.DataFrame):\n",
    "    # Compute features and bins (idempotent)\n",
    "    dd = df_full.copy()\n",
    "    if \"n_tokens_ws\" not in dd.columns:\n",
    "        dd = compute_length_features(dd, \"generation\")\n",
    "    if \"length_bin\" not in dd.columns or dd[\"length_bin\"].isna().any():\n",
    "        dd = assign_length_bins(dd, \"n_tokens_ws\")\n",
    "\n",
    "    # Small\n",
    "    small_df, small_diag = stratified_sample(dd, SIZE_SMALL, LENGTH_WEIGHTS, ai_models_even=True, random_state=RANDOM_SEED+1)\n",
    "    # Medium\n",
    "    med_df, med_diag = stratified_sample(dd, SIZE_MEDIUM, LENGTH_WEIGHTS, ai_models_even=True, random_state=RANDOM_SEED+2)\n",
    "    # Large\n",
    "    large_df, large_diag = stratified_sample(dd, SIZE_LARGE, LENGTH_WEIGHTS, ai_models_even=True, random_state=RANDOM_SEED+3)\n",
    "\n",
    "    # Save\n",
    "    small_df.to_csv(OUT_SMALL, index=False)\n",
    "    med_df.to_csv(OUT_MEDIUM, index=False)\n",
    "    large_df.to_csv(OUT_LARGE, index=False)\n",
    "\n",
    "    return (small_df, small_diag), (med_df, med_diag), (large_df, large_diag)\n",
    "\n",
    "# Execute if data present\n",
    "if len(df) > 0:\n",
    "    (small_df, small_diag), (med_df, med_diag), (large_df, large_diag) = run_all_samples(df)\n",
    "    print(\"Saved:\")\n",
    "    print(OUT_SMALL, len(small_df))\n",
    "    print(OUT_MEDIUM, len(med_df))\n",
    "    print(OUT_LARGE, len(large_df))\n",
    "else:\n",
    "    print(\"[INFO] No data loaded. Ensure TRAIN_CSV/TEST_CSV paths are correct and re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4d71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validator ready. Example usage after sampling:\n",
      "check_balance(small_df, SIZE_SMALL)\n"
     ]
    }
   ],
   "source": [
    "#  Validation utilities strict balance and ratios\n",
    "\n",
    "def check_balance(df_sample: pd.DataFrame, expected_total: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a table comparing actual vs target counts for:\n",
    "    - total\n",
    "    - human vs ai\n",
    "    - length bins overall\n",
    "    - length bins within source_type\n",
    "    - AI models evenness\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if len(df_sample) == 0:\n",
    "        return pd.DataFrame(columns=[\"dimension\",\"category\",\"actual\",\"target\"])\n",
    "\n",
    "    # Totals\n",
    "    rows.append((\"total\", \"all\", len(df_sample), expected_total))\n",
    "\n",
    "    # Human vs AI\n",
    "    for k, grp in df_sample.groupby(\"source_type\"):\n",
    "        rows.append((\"source_type\", k, len(grp), expected_total/2))\n",
    "\n",
    "    # Length bins overall\n",
    "    for lb, w in LENGTH_WEIGHTS.items():\n",
    "        target = expected_total * w\n",
    "        rows.append((\"length_bin\", lb, int((df_sample[\"length_bin\"]==lb).sum()), target))\n",
    "\n",
    "    # Length bins within source\n",
    "    for k, grp in df_sample.groupby(\"source_type\"):\n",
    "        for lb, w in LENGTH_WEIGHTS.items():\n",
    "            target = (expected_total/2) * w\n",
    "            rows.append((f\"length_bin|{k}\", lb, int((grp[\"length_bin\"]==lb).sum()), target))\n",
    "\n",
    "    # AI models evenness (only within AI)\n",
    "    ai_df = df_sample[df_sample[\"source_type\"]==\"ai\"]\n",
    "    if len(ai_df) > 0:\n",
    "        models_present = sorted(set(ai_df[\"model\"]) & set(AI_MODELS))\n",
    "        if models_present:\n",
    "            per_model_target = (expected_total/2) / len(models_present)\n",
    "            for m in models_present:\n",
    "                rows.append((\"ai_model\", m, int((ai_df[\"model\"]==m).sum()), per_model_target))\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"dimension\",\"category\",\"actual\",\"target\"])\n",
    "\n",
    "print(\"Validator ready. Example usage after sampling:\")\n",
    "print(\"check_balance(small_df, SIZE_SMALL)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3676ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>category</th>\n",
       "      <th>actual</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total</td>\n",
       "      <td>all</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source_type</td>\n",
       "      <td>ai</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_type</td>\n",
       "      <td>human</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>short</td>\n",
       "      <td>750</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>medium</td>\n",
       "      <td>750</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>long</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>short</td>\n",
       "      <td>375</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>medium</td>\n",
       "      <td>375</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>long</td>\n",
       "      <td>750</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>short</td>\n",
       "      <td>375</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>medium</td>\n",
       "      <td>375</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>long</td>\n",
       "      <td>750</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>139</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>cohere</td>\n",
       "      <td>137</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>cohere-chat</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mistral</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mpt</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>136</td>\n",
       "      <td>136.363636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dimension      category  actual       target\n",
       "0              total           all    3000  3000.000000\n",
       "1        source_type            ai    1500  1500.000000\n",
       "2        source_type         human    1500  1500.000000\n",
       "3         length_bin         short     750   750.000000\n",
       "4         length_bin        medium     750   750.000000\n",
       "5         length_bin          long    1500  1500.000000\n",
       "6      length_bin|ai         short     375   375.000000\n",
       "7      length_bin|ai        medium     375   375.000000\n",
       "8      length_bin|ai          long     750   750.000000\n",
       "9   length_bin|human         short     375   375.000000\n",
       "10  length_bin|human        medium     375   375.000000\n",
       "11  length_bin|human          long     750   750.000000\n",
       "12          ai_model       chatgpt     139   136.363636\n",
       "13          ai_model        cohere     137   136.363636\n",
       "14          ai_model   cohere-chat     136   136.363636\n",
       "15          ai_model          gpt2     136   136.363636\n",
       "16          ai_model          gpt3     136   136.363636\n",
       "17          ai_model          gpt4     136   136.363636\n",
       "18          ai_model    llama-chat     136   136.363636\n",
       "19          ai_model       mistral     136   136.363636\n",
       "20          ai_model  mistral-chat     136   136.363636\n",
       "21          ai_model           mpt     136   136.363636\n",
       "22          ai_model      mpt-chat     136   136.363636"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_balance(small_df, SIZE_SMALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bcbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>category</th>\n",
       "      <th>actual</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total</td>\n",
       "      <td>all</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source_type</td>\n",
       "      <td>ai</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_type</td>\n",
       "      <td>human</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>short</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>medium</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>long</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>short</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>medium</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>long</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>short</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>medium</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>long</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>547</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>cohere</td>\n",
       "      <td>547</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>cohere-chat</td>\n",
       "      <td>547</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>547</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>545</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>545</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>545</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mistral</td>\n",
       "      <td>545</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>544</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mpt</td>\n",
       "      <td>544</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>544</td>\n",
       "      <td>545.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dimension      category  actual        target\n",
       "0              total           all   12000  12000.000000\n",
       "1        source_type            ai    6000   6000.000000\n",
       "2        source_type         human    6000   6000.000000\n",
       "3         length_bin         short    3000   3000.000000\n",
       "4         length_bin        medium    3000   3000.000000\n",
       "5         length_bin          long    6000   6000.000000\n",
       "6      length_bin|ai         short    1500   1500.000000\n",
       "7      length_bin|ai        medium    1500   1500.000000\n",
       "8      length_bin|ai          long    3000   3000.000000\n",
       "9   length_bin|human         short    1500   1500.000000\n",
       "10  length_bin|human        medium    1500   1500.000000\n",
       "11  length_bin|human          long    3000   3000.000000\n",
       "12          ai_model       chatgpt     547    545.454545\n",
       "13          ai_model        cohere     547    545.454545\n",
       "14          ai_model   cohere-chat     547    545.454545\n",
       "15          ai_model          gpt2     547    545.454545\n",
       "16          ai_model          gpt3     545    545.454545\n",
       "17          ai_model          gpt4     545    545.454545\n",
       "18          ai_model    llama-chat     545    545.454545\n",
       "19          ai_model       mistral     545    545.454545\n",
       "20          ai_model  mistral-chat     544    545.454545\n",
       "21          ai_model           mpt     544    545.454545\n",
       "22          ai_model      mpt-chat     544    545.454545"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_balance(med_df, SIZE_MEDIUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a7857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>category</th>\n",
       "      <th>actual</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total</td>\n",
       "      <td>all</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source_type</td>\n",
       "      <td>ai</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_type</td>\n",
       "      <td>human</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>short</td>\n",
       "      <td>15000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>medium</td>\n",
       "      <td>15000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>length_bin</td>\n",
       "      <td>long</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>short</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>medium</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>length_bin|ai</td>\n",
       "      <td>long</td>\n",
       "      <td>15000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>short</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>medium</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>length_bin|human</td>\n",
       "      <td>long</td>\n",
       "      <td>15000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>cohere</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>cohere-chat</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>2728</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mistral</td>\n",
       "      <td>2727</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>2727</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mpt</td>\n",
       "      <td>2725</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ai_model</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>2725</td>\n",
       "      <td>2727.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dimension      category  actual        target\n",
       "0              total           all   60000  60000.000000\n",
       "1        source_type            ai   30000  30000.000000\n",
       "2        source_type         human   30000  30000.000000\n",
       "3         length_bin         short   15000  15000.000000\n",
       "4         length_bin        medium   15000  15000.000000\n",
       "5         length_bin          long   30000  30000.000000\n",
       "6      length_bin|ai         short    7500   7500.000000\n",
       "7      length_bin|ai        medium    7500   7500.000000\n",
       "8      length_bin|ai          long   15000  15000.000000\n",
       "9   length_bin|human         short    7500   7500.000000\n",
       "10  length_bin|human        medium    7500   7500.000000\n",
       "11  length_bin|human          long   15000  15000.000000\n",
       "12          ai_model       chatgpt    2728   2727.272727\n",
       "13          ai_model        cohere    2728   2727.272727\n",
       "14          ai_model   cohere-chat    2728   2727.272727\n",
       "15          ai_model          gpt2    2728   2727.272727\n",
       "16          ai_model          gpt3    2728   2727.272727\n",
       "17          ai_model          gpt4    2728   2727.272727\n",
       "18          ai_model    llama-chat    2728   2727.272727\n",
       "19          ai_model       mistral    2727   2727.272727\n",
       "20          ai_model  mistral-chat    2727   2727.272727\n",
       "21          ai_model           mpt    2725   2727.272727\n",
       "22          ai_model      mpt-chat    2725   2727.272727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_balance(large_df, SIZE_LARGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
