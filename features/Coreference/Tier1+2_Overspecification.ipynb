{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx9nCHilm4DD"
      },
      "outputs": [],
      "source": [
        "# Cell 1A: Check GPU availability\n",
        "\"\"\"\n",
        "Verify GPU is available and accessible\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"GPU Check:\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected. Will use CPU (slower)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1B: Install dependencies\n",
        "\"\"\"\n",
        "Installation cell - run once at notebook start\n",
        "\"\"\"\n",
        "\n",
        "!pip install fastcoref -q\n",
        "!pip install spacy -q\n",
        "!python -m spacy download en_core_web_trf -q\n",
        "\n",
        "print(\"Dependencies installed successfully\")"
      ],
      "metadata": {
        "id": "pHVUCn4znX9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import libraries\n",
        "\"\"\"\n",
        "All necessary imports\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fastcoref import FCoref\n",
        "import spacy\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "import json\n",
        "import pickle\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ],
      "metadata": {
        "id": "--qchb1-nZBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Initialize models\n",
        "\"\"\"\n",
        "Load FastCoref and spaCy with full pipeline for REG analysis\n",
        "Important: Keep parser and tagger enabled for dependency analysis\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Determine device\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = 'cpu'\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Initialize FastCoref\n",
        "print(\"\\nInitializing FastCoref model...\")\n",
        "coref_model = FCoref(device=device)\n",
        "\n",
        "# Initialize spaCy with necessary components for REG analysis\n",
        "# Keep: tokenizer, tagger, parser (needed for dependency analysis)\n",
        "# Disable: ner, lemmatizer (not needed, saves memory)\n",
        "print(\"Loading spaCy with parser and tagger...\")\n",
        "nlp = spacy.load(\"en_core_web_trf\", disable=[\"ner\", \"lemmatizer\"])\n",
        "\n",
        "print(\"\\nModels ready\")\n",
        "print(f\"FastCoref device: {device}\")\n",
        "print(f\"spaCy components: {nlp.pipe_names}\")\n",
        "print(\"Note: Parser enabled for dependency analysis (Tier 2)\")"
      ],
      "metadata": {
        "id": "XK4OUQ5rothf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load dataset\n",
        "\"\"\"\n",
        "Load RAID dataset\n",
        "Adjust path as needed\n",
        "\"\"\"\n",
        "\n",
        "# Load data - UPDATE THIS PATH\n",
        "df = pd.read_csv('/content/raid_sample_medium_PostPOS_CLEAN (1).csv')\n",
        "\n",
        "print(f\"Dataset loaded: {len(df)} samples\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Identify label column\n",
        "if 'is_ai' in df.columns:\n",
        "    label_column = 'is_ai'\n",
        "elif 'label' in df.columns:\n",
        "    label_column = 'label'\n",
        "else:\n",
        "    print(\"WARNING: No label column found\")\n",
        "    label_column = None\n",
        "\n",
        "if label_column:\n",
        "    print(f\"\\nLabel column: '{label_column}'\")\n",
        "    print(f\"Class distribution:\")\n",
        "    print(df[label_column].value_counts())\n",
        "\n",
        "print(f\"\\nFirst sample preview:\")\n",
        "print(f\"Text: {df['generation'].iloc[0][:200]}...\")"
      ],
      "metadata": {
        "id": "ovy2fEgOovCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Chain extraction from FastCoref\n",
        "\"\"\"\n",
        "Extract coreference chains with full mention metadata\n",
        "\"\"\"\n",
        "\n",
        "def get_sentence_index(doc, token_idx: int) -> int:\n",
        "    \"\"\"Get sentence index for a token position\"\"\"\n",
        "    for sent_idx, sent in enumerate(doc.sents):\n",
        "        if sent.start <= token_idx < sent.end:\n",
        "            return sent_idx\n",
        "    return 0\n",
        "\n",
        "\n",
        "def extract_chains_from_fastcoref(text: str, coref_model, nlp) -> Tuple[List[List[Dict]], List[Dict], object]:\n",
        "    \"\"\"\n",
        "    Extract coreference chains using FastCoref\n",
        "\n",
        "    Returns:\n",
        "        chains: List of chains, each chain is list of mention dicts\n",
        "        all_mentions: Flat list of all mentions across all chains\n",
        "        doc: spaCy Doc object (for further analysis)\n",
        "    \"\"\"\n",
        "    chains = []\n",
        "    all_mentions = []\n",
        "\n",
        "    if not text or len(text.strip()) < 10:\n",
        "        return chains, all_mentions, None\n",
        "\n",
        "    try:\n",
        "        # Get predictions from FastCoref\n",
        "        preds = coref_model.predict(texts=[text])\n",
        "\n",
        "        if not preds or len(preds) == 0:\n",
        "            return chains, all_mentions, None\n",
        "\n",
        "        # Get clusters as character spans\n",
        "        coref_result = preds[0]\n",
        "        clusters = coref_result.get_clusters(as_strings=False)\n",
        "\n",
        "        if not clusters:\n",
        "            return chains, all_mentions, None\n",
        "\n",
        "        # Process with spaCy for token and sentence information\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Build token index mapping from character positions\n",
        "        char_to_token = {}\n",
        "        for token in doc:\n",
        "            for char_idx in range(token.idx, token.idx + len(token.text)):\n",
        "                char_to_token[char_idx] = token.i\n",
        "\n",
        "        # Convert each cluster to our format\n",
        "        for cluster in clusters:\n",
        "            chain_mentions = []\n",
        "\n",
        "            for char_start, char_end in cluster:\n",
        "                # Convert character span to token span\n",
        "                start_token_idx = char_to_token.get(char_start)\n",
        "                end_token_idx = char_to_token.get(char_end - 1)\n",
        "\n",
        "                if start_token_idx is None or end_token_idx is None:\n",
        "                    continue\n",
        "\n",
        "                # Get the span\n",
        "                span = doc[start_token_idx:end_token_idx + 1]\n",
        "\n",
        "                # Check if mention is a pronoun\n",
        "                if len(span) == 1:\n",
        "                    is_pronoun = span[0].pos_ == \"PRON\"\n",
        "                else:\n",
        "                    is_pronoun = span.root.pos_ == \"PRON\"\n",
        "\n",
        "                # Get sentence index\n",
        "                sent_idx = get_sentence_index(doc, start_token_idx)\n",
        "\n",
        "                # Get token indices list\n",
        "                token_indices = list(range(start_token_idx, end_token_idx + 1))\n",
        "\n",
        "                # Create mention dictionary with EXTENDED info for REG analysis\n",
        "                mention_dict = {\n",
        "                    'text': span.text,\n",
        "                    'start_token': start_token_idx,\n",
        "                    'end_token': end_token_idx + 1,\n",
        "                    'start_char': char_start,\n",
        "                    'end_char': char_end,\n",
        "                    'sent_idx': sent_idx,\n",
        "                    'is_pronoun': is_pronoun,\n",
        "                    'token_count': len(span),\n",
        "                    'token_indices': token_indices,\n",
        "                    # NEW: Store spaCy span for later analysis\n",
        "                    'span_start': start_token_idx,\n",
        "                    'span_end': end_token_idx + 1\n",
        "                }\n",
        "\n",
        "                chain_mentions.append(mention_dict)\n",
        "                all_mentions.append(mention_dict)\n",
        "\n",
        "            if chain_mentions:\n",
        "                # Sort mentions by position in document\n",
        "                chain_mentions.sort(key=lambda m: m['start_token'])\n",
        "                chains.append(chain_mentions)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in coreference extraction: {e}\")\n",
        "        return chains, all_mentions, None\n",
        "\n",
        "    return chains, all_mentions, doc\n",
        "\n",
        "\n",
        "print(\"Chain extraction function defined\")"
      ],
      "metadata": {
        "id": "rltrSc2BowxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Test chain extraction\n",
        "\"\"\"\n",
        "Test on example to verify everything works\n",
        "\"\"\"\n",
        "\n",
        "test_text = \"We are so happy to see you using our coref package. This package is very fast!\"\n",
        "\n",
        "print(\"Testing FastCoref extraction...\")\n",
        "print(f\"Text: {test_text}\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Test extraction\n",
        "test_chains, test_mentions, test_doc = extract_chains_from_fastcoref(test_text, coref_model, nlp)\n",
        "\n",
        "print(f\"Chains detected: {len(test_chains)}\")\n",
        "print(f\"Total mentions: {len(test_mentions)}\")\n",
        "\n",
        "for chain_idx, chain in enumerate(test_chains):\n",
        "    print(f\"\\nChain {chain_idx}:\")\n",
        "    for mention in chain:\n",
        "        print(f\"  '{mention['text']}' (tokens {mention['start_token']}-{mention['end_token']}, \"\n",
        "              f\"sent {mention['sent_idx']}, pronoun={mention['is_pronoun']}, \"\n",
        "              f\"token_count={mention['token_count']})\")"
      ],
      "metadata": {
        "id": "oVNMPG6joygn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: TIER 1 - RMO (Repeat-Mention Overspecification) Features\n",
        "\"\"\"\n",
        "Tier 1: Analyze repeat mentions for overspecification\n",
        "\n",
        "3 features:\n",
        "1. repeat_mention_expansion_rate: How often repeat mentions add tokens\n",
        "2. avg_tokens_added_on_repeat: Mean additional tokens when expanding\n",
        "3. repeat_overspecification_ratio: Proportion of expansions that are unnecessary\n",
        "\"\"\"\n",
        "\n",
        "def calculate_tier1_rmo_features(chains: List[List[Dict]], doc) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculate Tier 1 RMO features\n",
        "\n",
        "    Core hypothesis: AI adds unnecessary modifiers when re-mentioning entities\n",
        "    Humans use minimal expressions for established referents\n",
        "    \"\"\"\n",
        "    features = {\n",
        "        'repeat_mention_expansion_rate': 0.0,\n",
        "        'avg_tokens_added_on_repeat': 0.0,\n",
        "        'repeat_overspecification_ratio': 0.0\n",
        "    }\n",
        "\n",
        "    if not chains or doc is None:\n",
        "        return features\n",
        "\n",
        "    # Track repeat mentions (2nd+ mentions in each chain)\n",
        "    repeat_mentions = []\n",
        "    expansions = []\n",
        "    unnecessary_expansions = []\n",
        "\n",
        "    for chain in chains:\n",
        "        if len(chain) < 2:\n",
        "            continue\n",
        "\n",
        "        # First mention establishes baseline\n",
        "        first_mention = chain[0]\n",
        "        baseline_tokens = first_mention['token_count']\n",
        "        baseline_is_pronoun = first_mention['is_pronoun']\n",
        "\n",
        "        # Analyze subsequent mentions\n",
        "        for mention in chain[1:]:\n",
        "            repeat_mentions.append(mention)\n",
        "\n",
        "            current_tokens = mention['token_count']\n",
        "            current_is_pronoun = mention['is_pronoun']\n",
        "\n",
        "            # Check if mention expanded\n",
        "            if current_tokens > baseline_tokens:\n",
        "                expansion_amount = current_tokens - baseline_tokens\n",
        "                expansions.append(expansion_amount)\n",
        "\n",
        "                # Heuristic for \"unnecessary\" expansion:\n",
        "                # If previous mention was NOT a pronoun and context is same sentence\n",
        "                # or adjacent sentence, expansion is likely unnecessary\n",
        "                prev_mention = chain[chain.index(mention) - 1]\n",
        "                sent_distance = abs(mention['sent_idx'] - prev_mention['sent_idx'])\n",
        "\n",
        "                # Unnecessary if:\n",
        "                # 1. Previous mention was full NP (not pronoun)\n",
        "                # 2. Close in discourse (within 1 sentence)\n",
        "                # 3. Current mention adds tokens\n",
        "                if not prev_mention['is_pronoun'] and sent_distance <= 1:\n",
        "                    unnecessary_expansions.append(expansion_amount)\n",
        "\n",
        "    # Calculate features\n",
        "    if repeat_mentions:\n",
        "        # Feature 1: How often do repeat mentions expand?\n",
        "        expansion_count = len(expansions)\n",
        "        features['repeat_mention_expansion_rate'] = expansion_count / len(repeat_mentions)\n",
        "\n",
        "        # Feature 2: Average tokens added when expanding\n",
        "        if expansions:\n",
        "            features['avg_tokens_added_on_repeat'] = np.mean(expansions)\n",
        "\n",
        "        # Feature 3: Proportion of expansions that are unnecessary\n",
        "        if expansions:\n",
        "            features['repeat_overspecification_ratio'] = len(unnecessary_expansions) / len(expansions)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "print(\"Tier 1 RMO feature functions defined\")"
      ],
      "metadata": {
        "id": "_fUF3qt-o0sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: TIER 2 - MTA (Modification Type Analysis) Features\n",
        "\"\"\"\n",
        "Tier 2: Analyze types of modifications used in referring expressions\n",
        "\n",
        "5 features:\n",
        "1. adjective_modification_rate: Proportion of mentions with adjectives\n",
        "2. prepositional_modification_rate: Proportion with PP modifiers\n",
        "3. relative_clause_rate: Proportion with relative clauses\n",
        "4. modification_type_entropy: Diversity of modification types\n",
        "5. avg_modifiers_per_mention: Mean modification complexity\n",
        "\"\"\"\n",
        "\n",
        "def analyze_mention_modifications(mention: Dict, doc) -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Analyze syntactic modifications in a mention using spaCy dependencies\n",
        "\n",
        "    Returns dict with counts for each modification type\n",
        "    \"\"\"\n",
        "    mods = {\n",
        "        'amod': 0,        # Adjective modifiers\n",
        "        'prep': 0,        # Prepositional phrases\n",
        "        'relcl': 0,       # Relative clauses\n",
        "        'compound': 0,    # Compound modifiers\n",
        "        'det': 0,         # Determiners (for reference)\n",
        "        'poss': 0,        # Possessive modifiers\n",
        "    }\n",
        "\n",
        "    # Get span from doc\n",
        "    start_idx = mention['span_start']\n",
        "    end_idx = mention['span_end']\n",
        "    span = doc[start_idx:end_idx]\n",
        "\n",
        "    # Analyze dependencies within span\n",
        "    for token in span:\n",
        "        dep = token.dep_\n",
        "\n",
        "        if dep == 'amod':\n",
        "            mods['amod'] += 1\n",
        "        elif dep in ['prep', 'pobj']:\n",
        "            mods['prep'] += 1\n",
        "        elif dep == 'relcl':\n",
        "            mods['relcl'] += 1\n",
        "        elif dep == 'compound':\n",
        "            mods['compound'] += 1\n",
        "        elif dep == 'det':\n",
        "            mods['det'] += 1\n",
        "        elif dep in ['poss', 'nmod:poss']:\n",
        "            mods['poss'] += 1\n",
        "\n",
        "    return mods\n",
        "\n",
        "\n",
        "def calculate_tier2_mta_features(chains: List[List[Dict]], all_mentions: List[Dict], doc) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculate Tier 2 MTA features\n",
        "\n",
        "    Core hypothesis: AI and humans differ in HOW they modify expressions\n",
        "    AI may prefer certain modification types (e.g., adjective stacking)\n",
        "    \"\"\"\n",
        "    features = {\n",
        "        'adjective_modification_rate': 0.0,\n",
        "        'prepositional_modification_rate': 0.0,\n",
        "        'relative_clause_rate': 0.0,\n",
        "        'modification_type_entropy': 0.0,\n",
        "        'avg_modifiers_per_mention': 0.0\n",
        "    }\n",
        "\n",
        "    if not all_mentions or doc is None:\n",
        "        return features\n",
        "\n",
        "    # Analyze all mentions\n",
        "    mention_mod_counts = []\n",
        "    modification_types = []\n",
        "\n",
        "    for mention in all_mentions:\n",
        "        # Skip pronouns (they don't have complex modifications)\n",
        "        if mention['is_pronoun']:\n",
        "            continue\n",
        "\n",
        "        mods = analyze_mention_modifications(mention, doc)\n",
        "        mention_mod_counts.append(sum(mods.values()))\n",
        "\n",
        "        # Track which types are used\n",
        "        if mods['amod'] > 0:\n",
        "            modification_types.append('amod')\n",
        "        if mods['prep'] > 0:\n",
        "            modification_types.append('prep')\n",
        "        if mods['relcl'] > 0:\n",
        "            modification_types.append('relcl')\n",
        "        if mods['compound'] > 0:\n",
        "            modification_types.append('compound')\n",
        "        if mods['poss'] > 0:\n",
        "            modification_types.append('poss')\n",
        "\n",
        "    non_pronoun_mentions = len([m for m in all_mentions if not m['is_pronoun']])\n",
        "\n",
        "    if non_pronoun_mentions > 0:\n",
        "        # Feature 1: Adjective modification rate\n",
        "        amod_count = sum(1 for m in all_mentions\n",
        "                         if not m['is_pronoun'] and\n",
        "                         analyze_mention_modifications(m, doc)['amod'] > 0)\n",
        "        features['adjective_modification_rate'] = amod_count / non_pronoun_mentions\n",
        "\n",
        "        # Feature 2: Prepositional modification rate\n",
        "        prep_count = sum(1 for m in all_mentions\n",
        "                         if not m['is_pronoun'] and\n",
        "                         analyze_mention_modifications(m, doc)['prep'] > 0)\n",
        "        features['prepositional_modification_rate'] = prep_count / non_pronoun_mentions\n",
        "\n",
        "        # Feature 3: Relative clause rate\n",
        "        relcl_count = sum(1 for m in all_mentions\n",
        "                          if not m['is_pronoun'] and\n",
        "                          analyze_mention_modifications(m, doc)['relcl'] > 0)\n",
        "        features['relative_clause_rate'] = relcl_count / non_pronoun_mentions\n",
        "\n",
        "        # Feature 4: Modification type entropy (diversity)\n",
        "        if modification_types:\n",
        "            type_counts = Counter(modification_types)\n",
        "            total = sum(type_counts.values())\n",
        "            probs = [count / total for count in type_counts.values()]\n",
        "            entropy = -sum(p * np.log2(p) for p in probs if p > 0)\n",
        "            features['modification_type_entropy'] = entropy\n",
        "\n",
        "        # Feature 5: Average modifiers per mention\n",
        "        if mention_mod_counts:\n",
        "            features['avg_modifiers_per_mention'] = np.mean(mention_mod_counts)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "print(\"Tier 2 MTA feature functions defined\")"
      ],
      "metadata": {
        "id": "rzjjvcuOo97v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Integrated feature extraction function\n",
        "\"\"\"\n",
        "Extract ALL features: Baseline + Tier 1 + Tier 2\n",
        "\"\"\"\n",
        "\n",
        "def extract_all_coref_features(text: str, coref_model, nlp) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Extract all coreference features from text\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with 14 features:\n",
        "        - 6 baseline features\n",
        "        - 3 Tier 1 (RMO) features\n",
        "        - 5 Tier 2 (MTA) features\n",
        "    \"\"\"\n",
        "    # Initialize all features with defaults\n",
        "    features = {\n",
        "        # Tier 1: RMO\n",
        "        'repeat_mention_expansion_rate': 0.0,\n",
        "        'avg_tokens_added_on_repeat': 0.0,\n",
        "        'repeat_overspecification_ratio': 0.0,\n",
        "        # Tier 2: MTA\n",
        "        'adjective_modification_rate': 0.0,\n",
        "        'prepositional_modification_rate': 0.0,\n",
        "        'relative_clause_rate': 0.0,\n",
        "        'modification_type_entropy': 0.0,\n",
        "        'avg_modifiers_per_mention': 0.0\n",
        "    }\n",
        "\n",
        "    # Handle empty text\n",
        "    if not text or len(text.strip()) < 10:\n",
        "        return features\n",
        "\n",
        "    try:\n",
        "        # Extract chains\n",
        "        chains, all_mentions, doc = extract_chains_from_fastcoref(text, coref_model, nlp)\n",
        "\n",
        "        if not all_mentions or doc is None:\n",
        "            return features\n",
        "\n",
        "        doc_length = len(doc)\n",
        "\n",
        "        # === TIER 1: RMO FEATURES ===\n",
        "        tier1_features = calculate_tier1_rmo_features(chains, doc)\n",
        "        features.update(tier1_features)\n",
        "\n",
        "        # === TIER 2: MTA FEATURES ===\n",
        "        tier2_features = calculate_tier2_mta_features(chains, all_mentions, doc)\n",
        "        features.update(tier2_features)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        # Return zeros on error\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "print(\"Integrated feature extraction function defined\")"
      ],
      "metadata": {
        "id": "i4Hswo-wpEdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Batch processing with chain persistence\n",
        "\"\"\"\n",
        "Process dataframe with CHAIN SAVING for future analysis\n",
        "\"\"\"\n",
        "\n",
        "def extract_coref_features_batch_with_chains(df: pd.DataFrame,\n",
        "                                               text_column: str,\n",
        "                                               coref_model,\n",
        "                                               nlp,\n",
        "                                               batch_size: int = 32,\n",
        "                                               save_chains: bool = True) -> Tuple[pd.DataFrame, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Extract features for entire dataframe WITH chain persistence\n",
        "\n",
        "    Returns:\n",
        "        df_result: DataFrame with features\n",
        "        chains_data: List of chain structures (if save_chains=True)\n",
        "    \"\"\"\n",
        "    print(f\"Extracting features from {len(df)} texts...\")\n",
        "    print(f\"Text column: '{text_column}'\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Save chains: {save_chains}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # Initialize result dataframe\n",
        "    df_result = df.copy()\n",
        "\n",
        "    # Initialize feature columns\n",
        "    feature_names = [\n",
        "        # Tier 1\n",
        "        'repeat_mention_expansion_rate', 'avg_tokens_added_on_repeat',\n",
        "        'repeat_overspecification_ratio',\n",
        "        # Tier 2\n",
        "        'adjective_modification_rate', 'prepositional_modification_rate',\n",
        "        'relative_clause_rate', 'modification_type_entropy',\n",
        "        'avg_modifiers_per_mention'\n",
        "    ]\n",
        "\n",
        "    for feature_name in feature_names:\n",
        "        df_result[feature_name] = 0.0\n",
        "\n",
        "    # Storage for chains\n",
        "    chains_data = [] if save_chains else None\n",
        "\n",
        "    # Prepare valid texts\n",
        "    valid_indices = []\n",
        "    valid_texts = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text = row[text_column]\n",
        "        if not pd.isna(text) and len(str(text).strip()) >= 10:\n",
        "            valid_indices.append(idx)\n",
        "            valid_texts.append(str(text))\n",
        "\n",
        "    print(f\"Valid texts for processing: {len(valid_texts)}/{len(df)}\")\n",
        "\n",
        "    # Process in batches\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    for batch_start in tqdm(range(0, len(valid_texts), batch_size), desc=\"Processing batches\"):\n",
        "        batch_end = min(batch_start + batch_size, len(valid_texts))\n",
        "        batch_texts = valid_texts[batch_start:batch_end]\n",
        "        batch_indices = valid_indices[batch_start:batch_end]\n",
        "\n",
        "        for text, idx in zip(batch_texts, batch_indices):\n",
        "            try:\n",
        "                # Extract features\n",
        "                features = extract_all_coref_features(text, coref_model, nlp)\n",
        "\n",
        "                # Store features\n",
        "                for feature_name, value in features.items():\n",
        "                    if np.isfinite(value):\n",
        "                        df_result.at[idx, feature_name] = value\n",
        "\n",
        "                # Save chains if requested\n",
        "                if save_chains:\n",
        "                    chains, all_mentions, doc = extract_chains_from_fastcoref(text, coref_model, nlp)\n",
        "\n",
        "                    # Serialize chains (remove doc reference)\n",
        "                    chains_serializable = [\n",
        "                        [\n",
        "                            {k: v for k, v in mention.items() if k not in ['span_start', 'span_end']}\n",
        "                            for mention in chain\n",
        "                        ]\n",
        "                        for chain in chains\n",
        "                    ]\n",
        "\n",
        "                    chains_data.append({\n",
        "                        'idx': idx,\n",
        "                        'chains': chains_serializable,\n",
        "                        'n_chains': len(chains),\n",
        "                        'n_mentions': len(all_mentions)\n",
        "                    })\n",
        "\n",
        "                if any(value > 0 for value in features.values()):\n",
        "                    successful += 1\n",
        "                else:\n",
        "                    failed += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                failed += 1\n",
        "                if save_chains:\n",
        "                    chains_data.append({\n",
        "                        'idx': idx,\n",
        "                        'chains': [],\n",
        "                        'n_chains': 0,\n",
        "                        'n_mentions': 0\n",
        "                    })\n",
        "                continue\n",
        "\n",
        "        # Periodic GPU memory cleanup\n",
        "        if torch.cuda.is_available() and batch_start % (batch_size * 10) == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nExtraction complete:\")\n",
        "    print(f\"Successful: {successful}/{len(valid_texts)}\")\n",
        "    print(f\"Failed: {failed}/{len(valid_texts)}\")\n",
        "    print(f\"Skipped (invalid): {len(df) - len(valid_texts)}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "\n",
        "    return df_result, chains_data\n",
        "\n",
        "\n",
        "print(\"Batch processing with chain persistence defined\")"
      ],
      "metadata": {
        "id": "2IPnfPMMpKAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Test on first 100 samples\n",
        "\"\"\"\n",
        "Test pipeline on small subset before running full dataset\n",
        "\"\"\"\n",
        "\n",
        "print(\"Testing on first 100 samples...\")\n",
        "df_test = df.head(100).copy()\n",
        "\n",
        "df_test_processed, chains_test = extract_coref_features_batch_with_chains(\n",
        "    df=df_test,\n",
        "    text_column='generation',\n",
        "    coref_model=coref_model,\n",
        "    nlp=nlp,\n",
        "    save_chains=True\n",
        ")\n",
        "\n",
        "# Check results\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FEATURE STATISTICS (100 samples)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "feature_names = [\n",
        "    'repeat_mention_expansion_rate', 'avg_tokens_added_on_repeat',\n",
        "    'repeat_overspecification_ratio', 'adjective_modification_rate',\n",
        "    'prepositional_modification_rate', 'relative_clause_rate',\n",
        "    'modification_type_entropy', 'avg_modifiers_per_mention'\n",
        "]\n",
        "\n",
        "print(\"\\nBASELINE FEATURES:\")\n",
        "for feature in feature_names[:6]:\n",
        "    values = df_test_processed[feature]\n",
        "    non_zero = (values > 0).sum()\n",
        "    print(f\"  {feature:30s}: mean={values.mean():.4f}, non-zero={non_zero}/100\")\n",
        "\n",
        "print(\"\\nTIER 1: RMO FEATURES:\")\n",
        "for feature in feature_names[6:9]:\n",
        "    values = df_test_processed[feature]\n",
        "    non_zero = (values > 0).sum()\n",
        "    print(f\"  {feature:30s}: mean={values.mean():.4f}, non-zero={non_zero}/100\")\n",
        "\n",
        "print(\"\\nTIER 2: MTA FEATURES:\")\n",
        "for feature in feature_names[9:]:\n",
        "    values = df_test_processed[feature]\n",
        "    non_zero = (values > 0).sum()\n",
        "    print(f\"  {feature:30s}: mean={values.mean():.4f}, non-zero={non_zero}/100\")\n",
        "\n",
        "# Save test results\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Saving test results...\")\n",
        "df_test_processed.to_csv('test_100_with_tier1_tier2_features.csv', index=False)\n",
        "\n",
        "with open('test_100_chains.pkl', 'wb') as f:\n",
        "    pickle.dump(chains_test, f)\n",
        "\n",
        "print(\"✓ Saved: test_100_with_tier1_tier2_features.csv\")\n",
        "print(\"✓ Saved: test_100_chains.pkl\")\n",
        "print(\"\\nIf results look good, proceed with full dataset extraction!\")"
      ],
      "metadata": {
        "id": "tFrpGU6upQ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Full dataset extraction with chunking\n",
        "\"\"\"\n",
        "Process full dataset in chunks with checkpoints\n",
        "ONLY RUN THIS AFTER VERIFYING TEST RESULTS\n",
        "\"\"\"\n",
        "\n",
        "# CONFIGURATION\n",
        "chunk_size = 1000\n",
        "n_chunks = int(np.ceil(len(df) / chunk_size))\n",
        "\n",
        "print(f\"Processing {len(df)} samples in {n_chunks} chunks of {chunk_size}\")\n",
        "print(f\"Estimated total time: ~10-12 hours\")\n",
        "print(\"\\nStarting chunked extraction...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results = []\n",
        "all_chains_data = []\n",
        "\n",
        "for chunk_idx in range(n_chunks):\n",
        "    start_idx = chunk_idx * chunk_size\n",
        "    end_idx = min((chunk_idx + 1) * chunk_size, len(df))\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"CHUNK {chunk_idx + 1}/{n_chunks}\")\n",
        "    print(f\"Samples {start_idx} to {end_idx}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Extract chunk\n",
        "    df_chunk = df.iloc[start_idx:end_idx].copy()\n",
        "\n",
        "    # Process chunk\n",
        "    df_chunk_processed, chains_chunk = extract_coref_features_batch_with_chains(\n",
        "        df=df_chunk,\n",
        "        text_column='generation',\n",
        "        coref_model=coref_model,\n",
        "        nlp=nlp,\n",
        "        save_chains=True\n",
        "    )\n",
        "\n",
        "    # Save chunk checkpoint\n",
        "    checkpoint_features_path = f'chunk_{chunk_idx+1}_of_{n_chunks}_features.csv'\n",
        "    checkpoint_chains_path = f'chunk_{chunk_idx+1}_of_{n_chunks}_chains.pkl'\n",
        "\n",
        "    df_chunk_processed.to_csv(checkpoint_features_path, index=False)\n",
        "    with open(checkpoint_chains_path, 'wb') as f:\n",
        "        pickle.dump(chains_chunk, f)\n",
        "\n",
        "    print(f\"✓ Checkpoint saved: {checkpoint_features_path}\")\n",
        "    print(f\"✓ Checkpoint saved: {checkpoint_chains_path}\")\n",
        "\n",
        "    results.append(df_chunk_processed)\n",
        "    all_chains_data.extend(chains_chunk)\n",
        "\n",
        "    # Clear GPU cache\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"GPU memory cleared: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "\n",
        "# Combine all chunks\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMBINING ALL CHUNKS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_with_features = pd.concat(results, ignore_index=True)\n",
        "\n",
        "# Save final results\n",
        "final_features_path = 'data_with_tier1_tier2_features_FINAL.csv'\n",
        "final_chains_path = 'data_chains_FINAL.pkl'\n",
        "\n",
        "df_with_features.to_csv(final_features_path, index=False)\n",
        "\n",
        "with open(final_chains_path, 'wb') as f:\n",
        "    pickle.dump(all_chains_data, f)\n",
        "\n",
        "print(f\"\\n✓ SUCCESS!\")\n",
        "print(f\"Total samples processed: {len(df_with_features)}\")\n",
        "print(f\"✓ Features saved: {final_features_path}\")\n",
        "print(f\"✓ Chains saved: {final_chains_path}\")\n",
        "\n",
        "# Quick summary\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL FEATURE SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for feature in feature_names:\n",
        "    values = df_with_features[feature]\n",
        "    non_zero = (values > 0).sum()\n",
        "    print(f\"{feature:35s}: mean={values.mean():.4f}, \"\n",
        "          f\"non-zero={non_zero}/{len(df_with_features)} \"\n",
        "          f\"({100*non_zero/len(df_with_features):.1f}%)\")"
      ],
      "metadata": {
        "id": "Hvcs_YPCpWSo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}